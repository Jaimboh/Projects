{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Definition\n",
        "\n",
        "Language detection is a Natural Language Processing (NLP) task that involves identifying the language of a text or document. A few years ago, using machine learning for language identification was a challenging endeavor due to the lack of data on languages. However, with the recent proliferation of data, powerful machine-learning models have been developed to facilitate language identification.\n",
        "As a human, you can easily recognize the languages you know. For instance, I can quickly identify Kiswahili and English, but being a Kenyan, it is not always possible for me to identify all Kenyan languages. This is where language identification technology can be of great help. Google Translate is one of the most widely used language translators in the world, with millions of people around the globe relying on it. It also includes a machine learning model to detect languages, which can be used if you are unsure of which language you want to translate.\n",
        "\n",
        "## Data Preparation\n",
        "\n",
        "The most crucial part of training a language detection model is data. The more data you have about each language, the more accurate your model will be in real-time. For this purpose, I am using a dataset collected from Kaggle, which contains data about 22 popular languages and 1000 sentences in each of the languages. This makes it an ideal dataset for training a language detection model with machine learning. In the section below, I will take you through the process of training a language detection model."
      ],
      "metadata": {
        "id": "aU6Xk0UGFQym"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c1rMxB6FJLx",
        "outputId": "b50f0cca-c68f-4c1d-aad3-c5b149e7d7e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Text  language\n",
            "0  klement gottwaldi surnukeha palsameeriti ning ...  Estonian\n",
            "1  sebes joseph pereira thomas  på eng the jesuit...   Swedish\n",
            "2  ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...      Thai\n",
            "3  விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...     Tamil\n",
            "4  de spons behoort tot het geslacht haliclona en...     Dutch\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/amankharwal/Website-data/master/dataset.csv\")\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have gotten our data ready we can check if there is null values and perform some data cleaning before we use it to train our model"
      ],
      "metadata": {
        "id": "5WaRcWcBHzYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UP4kZDTIEN1",
        "outputId": "c48a42d5-a0aa-44c1-d7fc-816638f57d49"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 22000 entries, 0 to 21999\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Text      22000 non-null  object\n",
            " 1   language  22000 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 343.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbopzeW8IJs0",
        "outputId": "abd72bab-9136-483b-eaca-42aab322731e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text        0\n",
              "language    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our dataset do not have any null values now we can proceed to have a look at the languages present in our dataset"
      ],
      "metadata": {
        "id": "z1uztVw-IS_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"language\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90NkyILSIRtE",
        "outputId": "f9530002-d71c-4a7c-9ee7-7437724179e5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Estonian      1000\n",
              "Swedish       1000\n",
              "English       1000\n",
              "Russian       1000\n",
              "Romanian      1000\n",
              "Persian       1000\n",
              "Pushto        1000\n",
              "Spanish       1000\n",
              "Hindi         1000\n",
              "Korean        1000\n",
              "Chinese       1000\n",
              "French        1000\n",
              "Portugese     1000\n",
              "Indonesian    1000\n",
              "Urdu          1000\n",
              "Latin         1000\n",
              "Turkish       1000\n",
              "Japanese      1000\n",
              "Dutch         1000\n",
              "Tamil         1000\n",
              "Thai          1000\n",
              "Arabic        1000\n",
              "Name: language, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset contains 22 languages with 1000 sentences from each language. This is a very balanced dataset with no missing values, so we can say this dataset is completely ready to be used to train a machine learning model."
      ],
      "metadata": {
        "id": "eqKwvRQsIvcH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Language Detection Model\n",
        "Now let’s split the data into training and test sets:"
      ],
      "metadata": {
        "id": "A55R4CY_I5au"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array(data[\"Text\"])\n",
        "y = np.array(data[\"language\"])\n",
        "\n",
        "cv = CountVectorizer()\n",
        "X = cv.fit_transform(x)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "                                                    test_size=0.30, \n",
        "                                                    random_state=42)"
      ],
      "metadata": {
        "id": "CbmRdBwfImBU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As this is a problem of multiclass classification, so I will be using the Multinomial Naïve Bayes algorithm to train the language detection model as this algorithm always performs very well on the problems based on multiclass classification"
      ],
      "metadata": {
        "id": "pJnCXs0yJQZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultinomialNB()\n",
        "model.fit(X_train,y_train)\n",
        "model.score(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSY5b6J3JR1R",
        "outputId": "0598f4d8-70e5-4242-aa00-f9237f334e97"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9528787878787879"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our model has a score of 95% which is quite good ,we can proceed and do some test by using a user input"
      ],
      "metadata": {
        "id": "LGLP-aQGJghV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user = input(\"Enter a Text: \")\n",
        "data = cv.transform([user]).toarray()\n",
        "output = model.predict(data)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_k7cfcdJyil",
        "outputId": "50d6a6e3-35b0-4b79-951d-9b7d3d87c33c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a Text: Добрый день! Меня зовут Иван, и я рад познакомиться с вами. Я живу в Москве и люблю исследовать город и его историю. В свободное время я люблю готовить и путешествовать. Как ваши дела?\n",
            "['Russian']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So as you can see that the model performs well. One thing to note here is that this model can only detect the languages mentioned in the dataset.\n",
        "\n",
        "\n",
        "## Conclusion\n",
        "A language detection model project is a type of machine learning project focused on automatically determining which language any given input text is written in. The goal of the project is to develop an algorithm that can accurately classify languages based on patterns within words, phrases, and sentences. To achieve this, researchers often collect data from various sources to create datasets for training their model. After creating the dataset, engineers train their models using supervised learning techniques such as support vector machines or neural networks. Once trained, the language detection model can then be tested against a test set of unseen data to assess its accuracy at predicting languages. Such projects are extremely beneficial in various natural language processing tasks like distinguishing source content during web crawls or automatic translation services.And like we have seen our model can help in that though on a large scale of more data to train on."
      ],
      "metadata": {
        "id": "cr2LHxwEOtLo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MxszpodFQaGX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}