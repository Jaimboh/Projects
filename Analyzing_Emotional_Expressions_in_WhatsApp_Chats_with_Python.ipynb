{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\"Want to learn how to analyze the sentiments of a WhatsApp chat using Python? Look no further! In this project, we will explore the process of analyzing patterns and relationships between individuals or groups in a WhatsApp chat through sentiment analysis. Whether you're interested in personal conversations or group chats, this article will guide you through the steps of using Python to analyze the emotions expressed in a WhatsApp conversation.\""
      ],
      "metadata": {
        "id": "Wu3ZsXeAUD39"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WhatsApp Chat Sentiment Analysis\n",
        "To analyze the sentiments of a WhatsApp chat, we need to collect data from WhatsApp. Most of you must be using this messaging app, so to collect data about your chat, simply follow the steps mentioned below:\n",
        "1. For iPhone:\n",
        "\n",
        "\n",
        "\n",
        " 1.Open your chat with a person or a group\n",
        "\n",
        " 2.Just tap on the profile of the person or the group\n",
        "\n",
        " 3.You will see an option to export chat down below\n",
        "\n",
        "2. For Android\n",
        "\n",
        "\n",
        " 1.Open your chat with a person or a group\n",
        "\n",
        " 2.Click on the three dots above\n",
        "\n",
        " 3.Click on more\n",
        " \n",
        " 4.Click on the export chat\n",
        "\n",
        "You will see an option to attach media while exporting your chat. For simplicity, it is best not to attach media. Finally, enter your email and you will find your WhatsApp chat in your inbox.\n",
        "\n",
        "\n",
        "## WhatsApp Chat Sentiment Analysis using Python\n",
        "Now letâ€™s start with the task of WhatsApp chat sentiment analysis with Python. Iâ€™ll start this task by defining some helper functions because the data we get from WhatsApp is not a dataset that is ready to be used for any kind of data science task. So, to prepare your data for the sentiment analysis task, just define all the functions as defined below:\n"
      ],
      "metadata": {
        "id": "7uqAESanUwxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdhJvs0IWy0l",
        "outputId": "582d88f5-b788-4b89-c30a-3bef8471f1d4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.2.0.tar.gz (240 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m240.9/240.9 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234926 sha256=20a1cabb63219d34662504bba532ada67243d14a3ee6a4a508107de0eaec0a19\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/62/9e/a6b27a681abcde69970dbc0326ff51955f3beac72f15696984\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-2.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XCMVIyKQT98U"
      },
      "outputs": [],
      "source": [
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import emoji\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "\n",
        "# Extract Time\n",
        "def date_time(s):\n",
        "    pattern = '^([0-9]+)(\\/)([0-9]+)(\\/)([0-9]+), ([0-9]+):([0-9]+)[ ]?(AM|PM|am|pm)? -'\n",
        "    result = re.match(pattern, s)\n",
        "    if result:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "# Find Authors or Contacts\n",
        "def find_author(s):\n",
        "    s = s.split(\":\")\n",
        "    if len(s)==2:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "# Finding Messages\n",
        "def getDatapoint(line):\n",
        "    splitline = line.split(' - ')\n",
        "    dateTime = splitline[0]\n",
        "    date, time = dateTime.split(\", \")\n",
        "    message = \" \".join(splitline[1:])\n",
        "    if find_author(message):\n",
        "        splitmessage = message.split(\": \")\n",
        "        author = splitmessage[0]\n",
        "        message = \" \".join(splitmessage[1:])\n",
        "    else:\n",
        "        author= None\n",
        "    return date, time, author, message"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It doesnâ€™t matter if you are using a group chat dataset or your conversation with one person. All the functions defined above will prepare your data for the task of sentiment analysis as well as for any data science task. Now here is how we can prepare the data we collected from WhatsApp by using the above functions:"
      ],
      "metadata": {
        "id": "Y7RaY0PvXNws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "conversation = '/content/drive/MyDrive/watsap data/WhatsApp Chat with Beryl Ogaje.txt'\n",
        "with open(conversation, encoding=\"utf-8\") as fp:\n",
        "    fp.readline()\n",
        "    messageBuffer = []\n",
        "    date, time, author = None, None, None\n",
        "    while True:\n",
        "        line = fp.readline()\n",
        "        if not line:\n",
        "            break\n",
        "        line = line.strip()\n",
        "        if date_time(line):\n",
        "            if len(messageBuffer) > 0:\n",
        "                data.append([date, time, author, ' '.join(messageBuffer)])\n",
        "            messageBuffer.clear()\n",
        "            date, time, author, message = getDatapoint(line)\n",
        "            messageBuffer.append(message)\n",
        "        else:\n",
        "            messageBuffer.append(line)"
      ],
      "metadata": {
        "id": "H49I0jivW8L9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now here is how we can analyze the sentiments of WhatsApp chat using Python:"
      ],
      "metadata": {
        "id": "_5C4OOdcZgqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.downloader.download('vader_lexicon')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y341xiFLZx9f",
        "outputId": "7da32501-365e-4869-9ac8-d236aeb9df1c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data, columns=[\"Date\", 'Time', 'Author', 'Message'])\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "data = df.dropna()\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sentiments = SentimentIntensityAnalyzer()\n",
        "data[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in data[\"Message\"]]\n",
        "data[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in data[\"Message\"]]\n",
        "data[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in data[\"Message\"]]\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oVkMGUUZiEn",
        "outputId": "5a603c1b-cb5d-443c-ddba-ae372e8e2445"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Date   Time                    Author  \\\n",
            "0 2022-01-19  14:49  TJ  Incoporation Limited   \n",
            "1 2022-01-19  16:22               Beryl Ogaje   \n",
            "2 2022-01-19  19:18  TJ  Incoporation Limited   \n",
            "3 2022-01-19  19:31               Beryl Ogaje   \n",
            "4 2022-01-19  19:36  TJ  Incoporation Limited   \n",
            "\n",
            "                                        Message  Positive  Negative  Neutral  \n",
            "0                                         Omera       0.0       0.0      1.0  \n",
            "1                 Me nataka tu kumshow nakudate       0.0       0.0      1.0  \n",
            "2                                       ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚       0.0       0.0      1.0  \n",
            "3                        Juu Sasa nitasema nini       0.0       0.0      1.0  \n",
            "4  Mimi sijui ðŸ˜‚ðŸ˜‚ðŸ˜‚we mwambie niskie anasema nini       0.0       0.0      1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x= sum(data[\"Positive\"])\n",
        "y = sum(data[\"Negative\"])\n",
        "z = sum(data[\"Neutral\"])\n",
        "\n",
        "def sentiment_score(a, b, c):\n",
        "    if (a>b) and (a>c):\n",
        "        print(\"Positive ðŸ˜Š \")\n",
        "    elif (b>a) and (b>c):\n",
        "        print(\"Negative ðŸ˜  \")\n",
        "    else:\n",
        "        print(\"Neutral ðŸ™‚ \")\n",
        "sentiment_score(x, y, z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxoo0R7-cmaY",
        "outputId": "6f8c2044-3c43-4948-d62b-3c00e13615de"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neutral ðŸ™‚ \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, the data I used indicates that most of the messages between me and the other person are neutral. Which means itâ€™s neither positive nor negative."
      ],
      "metadata": {
        "id": "wFeAbAGhc2-8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "In this project, we covered how to perform sentiment analysis on a WhatsApp chat using Python. WhatsApp provides a wealth of data for natural language processing tasks, such as sentiment analysis, which involves analyzing the emotions or opinions expressed in a piece of text. By following the steps outlined in this project, you can easily apply sentiment analysis to a WhatsApp chat to gain insights into the sentiment of the conversation. Additionally, this technique can be extended to other forms of text data for a wide range of applications in data science and beyond."
      ],
      "metadata": {
        "id": "R9DauV1Hc_Bg"
      }
    }
  ]
}