{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "A named entity refers to any real-world object that has a name, such as a person, place, organization, or product. For example, in the sentence, \"My name is Tom, and I am a Machine Learning Engineer,\" the name \"Tom,\" the field of study \"Machine Learning,\" and the profession \"Engineer\" are all named entities. In Machine Learning, Named Entity Recognition (NER) is a Natural Language Processing task used to identify named entities in a given text. NER is a powerful tool that can be used to extract valuable information from large amounts of text, making it an invaluable asset for our Machine Learning project."
      ],
      "metadata": {
        "id": "IlJ5q2AgeCQZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Data for Named Entity Recognition (NER)\n",
        "The dataset, that I will use for this task can be easily downloaded from here:https://raw.githubusercontent.com/amankharwal/Website-data/master/ner_dataset.csv. Now the first thing I will do is to load the data and have a look at it to know what I am working with."
      ],
      "metadata": {
        "id": "Z7OdDATMf830"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JyW8z-dNc8-W",
        "outputId": "0b566348-fd64-4616-8702-ea23bcd4dda9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Sentence #           Word  POS Tag\n",
              "0  Sentence: 1      Thousands  NNS   O\n",
              "1          NaN             of   IN   O\n",
              "2          NaN  demonstrators  NNS   O\n",
              "3          NaN           have  VBP   O\n",
              "4          NaN        marched  VBN   O"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cd140d61-7f55-4570-a23e-8c5a7bff561c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd140d61-7f55-4570-a23e-8c5a7bff561c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cd140d61-7f55-4570-a23e-8c5a7bff561c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cd140d61-7f55-4570-a23e-8c5a7bff561c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "data = pd.read_csv('/content/drive/MyDrive/filename/ner_dataset.csv', encoding= 'unicode_escape')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the data, we can see that the words are broken into columns which will represent our feature X, and the Tag column in the right will represent our label Y."
      ],
      "metadata": {
        "id": "zGSWG6q8jZqG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation for Neural Networks\n",
        "I will train a Neural Network for the task of Named Entity Recognition (NER). So we need to do some modifications in the data to prepare it in such a manner so that it can easily fit into a neutral network. I will start this step by extracting the mappings that are required to train the neural network:"
      ],
      "metadata": {
        "id": "oxZNrWqdjrAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import chain\n",
        "def get_dict_map(data, token_or_tag):\n",
        "    tok2idx = {}\n",
        "    idx2tok = {}\n",
        "    \n",
        "    if token_or_tag == 'token':\n",
        "        vocab = list(set(data['Word'].to_list()))\n",
        "    else:\n",
        "        vocab = list(set(data['Tag'].to_list()))\n",
        "    \n",
        "    idx2tok = {idx:tok for  idx, tok in enumerate(vocab)}\n",
        "    tok2idx = {tok:idx for  idx, tok in enumerate(vocab)}\n",
        "    return tok2idx, idx2tok\n",
        "token2idx, idx2token = get_dict_map(data, 'token')\n",
        "tag2idx, idx2tag = get_dict_map(data, 'tag')"
      ],
      "metadata": {
        "id": "sTaI0OeejgiV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I will transform the columns in the data to extract the sequential data for our neural network:"
      ],
      "metadata": {
        "id": "-Svrgqw3kkzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['Word_idx'] = data['Word'].map(token2idx)\n",
        "data['Tag_idx'] = data['Tag'].map(tag2idx)\n",
        "data_fillna = data.fillna(method='ffill', axis=0)\n",
        "# Groupby and collect columns\n",
        "data_group = data_fillna.groupby(\n",
        "['Sentence #'],as_index=False\n",
        ")['Word', 'POS', 'Tag', 'Word_idx', 'Tag_idx'].agg(lambda x: list(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fXZ6WC0kgsa",
        "outputId": "6eb46fa7-08ff-4c48-c43d-4b8a07fbd62a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-f8b936d5d036>:5: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  data_group = data_fillna.groupby(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I will split the data into training and test sets. I will create a function for splitting the data because the LSTM layers accept sequences of the same length only. So every sentence that appears as integer in the data must be padded with the same length:"
      ],
      "metadata": {
        "id": "tC7RdEdSkzLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lYF-b57lG2J",
        "outputId": "7914e08c-910e-4b8c-eb10-d2319b1db0db"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (2.9.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "def get_pad_train_test_val(data_group, data):\n",
        "\n",
        "    #get max token and tag length\n",
        "    n_token = len(list(set(data['Word'].to_list())))\n",
        "    n_tag = len(list(set(data['Tag'].to_list())))\n",
        "\n",
        "    #Pad tokens (X var)    \n",
        "    tokens = data_group['Word_idx'].tolist()\n",
        "    maxlen = max([len(s) for s in tokens])\n",
        "    pad_tokens = pad_sequences(tokens, maxlen=maxlen, dtype='int32', padding='post', value= n_token - 1)\n",
        "\n",
        "    #Pad Tags (y var) and convert it into one hot encoding\n",
        "    tags = data_group['Tag_idx'].tolist()\n",
        "    pad_tags = pad_sequences(tags, maxlen=maxlen, dtype='int32', padding='post', value= tag2idx[\"O\"])\n",
        "    n_tags = len(tag2idx)\n",
        "    pad_tags = [to_categorical(i, num_classes=n_tags) for i in pad_tags]\n",
        "    \n",
        "    #Split train, test and validation set\n",
        "    tokens_, test_tokens, tags_, test_tags = train_test_split(pad_tokens, pad_tags, test_size=0.1, train_size=0.9, random_state=2020)\n",
        "    train_tokens, val_tokens, train_tags, val_tags = train_test_split(tokens_,tags_,test_size = 0.25,train_size =0.75, random_state=2020)\n",
        "\n",
        "    print(\n",
        "        'train_tokens length:', len(train_tokens),\n",
        "        '\\ntrain_tokens length:', len(train_tokens),\n",
        "        '\\ntest_tokens length:', len(test_tokens),\n",
        "        '\\ntest_tags:', len(test_tags),\n",
        "        '\\nval_tokens:', len(val_tokens),\n",
        "        '\\nval_tags:', len(val_tags),\n",
        "    )\n",
        "    \n",
        "    return train_tokens, val_tokens, test_tokens, train_tags, val_tags, test_tags\n",
        "\n",
        "train_tokens, val_tokens, test_tokens, train_tags, val_tags, test_tags = get_pad_train_test_val(data_group, data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6sMlcM6k0lK",
        "outputId": "b04cd9cb-fe81-4dd1-932c-d20cc034a0f7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_tokens length: 32372 \n",
            "train_tokens length: 32372 \n",
            "test_tokens length: 4796 \n",
            "test_tags: 4796 \n",
            "val_tokens: 10791 \n",
            "val_tags: 10791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Neural Network for Named Entity Recognition (NER)\n",
        "Now, I will proceed with training the neural network architecture of our model. So let’s start with importing all the packages we need for training our neural network:"
      ],
      "metadata": {
        "id": "yhyKms2-l5s5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow\n",
        "from tensorflow.keras import Sequential, Model, Input\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from numpy.random import seed\n",
        "seed(12)\n",
        "tensorflow.random.set_seed(42)"
      ],
      "metadata": {
        "id": "oOPpXS2XmAaU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The layer below will take the dimensions from the LSTM layer and will give the maximum length and maximum tags as an output:"
      ],
      "metadata": {
        "id": "DsYS7YjhmTl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = len(list(set(data['Word'].to_list())))+1\n",
        "output_dim = 64\n",
        "input_length = max([len(s) for s in data_group['Word_idx'].tolist()])\n",
        "n_tags = len(tag2idx)"
      ],
      "metadata": {
        "id": "Q9Uoe-gsmUdg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I will create a helper function which will help us in giving the summary of every layer of the neural network model for Named Entity Recognition (NER):"
      ],
      "metadata": {
        "id": "AramW5c0mb5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bilstm_lstm_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add Embedding layer\n",
        "    model.add(Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length))\n",
        "\n",
        "    # Add bidirectional LSTM\n",
        "    model.add(Bidirectional(LSTM(units=output_dim, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode = 'concat'))\n",
        "\n",
        "    # Add LSTM\n",
        "    model.add(LSTM(units=output_dim, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
        "\n",
        "    # Add timeDistributed Layer\n",
        "    model.add(TimeDistributed(Dense(n_tags, activation=\"relu\")))\n",
        "\n",
        "    #Optimiser \n",
        "    # adam = k.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "7A4Z8_-QmgPv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I will create a helper function to train the Named Entity Recognition model:"
      ],
      "metadata": {
        "id": "NX_I2lB-mtk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(X, y, model):\n",
        "    loss = list()\n",
        "    for i in range(25):\n",
        "        # fit model for one epoch on this sequence\n",
        "        hist = model.fit(X, y, batch_size=1000, verbose=1, epochs=1, validation_split=0.2)\n",
        "        loss.append(hist.history['loss'][0])\n",
        "    return loss"
      ],
      "metadata": {
        "id": "00vKC1Dym7CF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Driver code:"
      ],
      "metadata": {
        "id": "Ss3v7e4snDGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame()\n",
        "model_bilstm_lstm = get_bilstm_lstm_model()\n",
        "plot_model(model_bilstm_lstm)\n",
        "results['with_add_lstm'] = train_model(train_tokens, np.array(train_tags), model_bilstm_lstm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xx_uBvunFGm",
        "outputId": "a03d078a-f78d-474c-bd28-b4838806094e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 104, 64)           2251456   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 104, 128)         66048     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 104, 64)           49408     \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 104, 17)          1105      \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,368,017\n",
            "Trainable params: 2,368,017\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "26/26 [==============================] - 86s 3s/step - loss: 1.0003 - accuracy: 0.9140 - val_loss: 0.2574 - val_accuracy: 0.9681\n",
            "26/26 [==============================] - 79s 3s/step - loss: 0.2677 - accuracy: 0.9677 - val_loss: 0.2527 - val_accuracy: 0.9681\n",
            "26/26 [==============================] - 82s 3s/step - loss: 0.2396 - accuracy: 0.9677 - val_loss: 0.1832 - val_accuracy: 0.9681\n",
            "26/26 [==============================] - 79s 3s/step - loss: 0.1924 - accuracy: 0.9677 - val_loss: 0.1697 - val_accuracy: 0.9681\n",
            "26/26 [==============================] - 85s 3s/step - loss: 0.1774 - accuracy: 0.9678 - val_loss: 0.1612 - val_accuracy: 0.9681\n",
            "26/26 [==============================] - 80s 3s/step - loss: 0.1655 - accuracy: 0.9678 - val_loss: 0.1637 - val_accuracy: 0.9682\n",
            "26/26 [==============================] - 82s 3s/step - loss: 0.1664 - accuracy: 0.9678 - val_loss: 0.1514 - val_accuracy: 0.9683\n",
            "26/26 [==============================] - 81s 3s/step - loss: 0.1486 - accuracy: 0.9679 - val_loss: 0.1449 - val_accuracy: 0.9683\n",
            "26/26 [==============================] - 80s 3s/step - loss: 0.1457 - accuracy: 0.9680 - val_loss: 0.1976 - val_accuracy: 0.9687\n",
            "26/26 [==============================] - 82s 3s/step - loss: 0.2297 - accuracy: 0.9653 - val_loss: 0.1702 - val_accuracy: 0.9684\n",
            "26/26 [==============================] - 80s 3s/step - loss: 0.1424 - accuracy: 0.9681 - val_loss: 0.1357 - val_accuracy: 0.9683\n",
            "26/26 [==============================] - 82s 3s/step - loss: 0.1275 - accuracy: 0.9681 - val_loss: 0.1336 - val_accuracy: 0.9685\n",
            "26/26 [==============================] - 80s 3s/step - loss: 0.1213 - accuracy: 0.9683 - val_loss: 0.1231 - val_accuracy: 0.9688\n",
            "26/26 [==============================] - 83s 3s/step - loss: 0.1081 - accuracy: 0.9685 - val_loss: 0.1146 - val_accuracy: 0.9689\n",
            "26/26 [==============================] - 80s 3s/step - loss: 0.0983 - accuracy: 0.9687 - val_loss: 0.1088 - val_accuracy: 0.9692\n",
            "26/26 [==============================] - 80s 3s/step - loss: 0.0938 - accuracy: 0.9690 - val_loss: 0.1057 - val_accuracy: 0.9694\n",
            "26/26 [==============================] - 83s 3s/step - loss: 0.0920 - accuracy: 0.9692 - val_loss: 0.1185 - val_accuracy: 0.9697\n",
            "26/26 [==============================] - 80s 3s/step - loss: 0.0971 - accuracy: 0.9694 - val_loss: 0.1061 - val_accuracy: 0.9701\n",
            "26/26 [==============================] - 83s 3s/step - loss: 0.0879 - accuracy: 0.9698 - val_loss: 0.1034 - val_accuracy: 0.9701\n",
            "26/26 [==============================] - 81s 3s/step - loss: 0.0852 - accuracy: 0.9698 - val_loss: 0.1025 - val_accuracy: 0.9702\n",
            "26/26 [==============================] - 80s 3s/step - loss: 0.0829 - accuracy: 0.9705 - val_loss: 0.1037 - val_accuracy: 0.9712\n",
            "26/26 [==============================] - 83s 3s/step - loss: 0.0826 - accuracy: 0.9711 - val_loss: 0.1025 - val_accuracy: 0.9709\n",
            "26/26 [==============================] - 81s 3s/step - loss: 0.0808 - accuracy: 0.9711 - val_loss: 0.1013 - val_accuracy: 0.9714\n",
            "26/26 [==============================] - 83s 3s/step - loss: 0.0772 - accuracy: 0.9719 - val_loss: 0.0997 - val_accuracy: 0.9721\n",
            "26/26 [==============================] - 80s 3s/step - loss: 0.0755 - accuracy: 0.9727 - val_loss: 0.1021 - val_accuracy: 0.9721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can see our model accuracy is quite good now we can go ahead and some testing on our model."
      ],
      "metadata": {
        "id": "MdQFkHHAvcRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the Named Entity Recognition (NER) Model:\n",
        "\n",
        "Now let’s test our model on a piece of text:"
      ],
      "metadata": {
        "id": "q_musCAhpSOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "text = nlp('Hi, My name is Tom odhiambo \\n I am from kenya \\n I want to work with Microsoft \\n Bill Gates is my inspiration')\n",
        "displacy.render(text, style = 'ent', jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "bnRaqjJppa05",
        "outputId": "24db125c-c21c-4a27-f003-b4147386819b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Hi, My name is \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Tom\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " odhiambo </br> I am from \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    kenya\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " </br> I want to work with \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Microsoft\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " </br> \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bill Gates\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " is my inspiration</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "Named entity recognition (NER) is a cool project. It uses natural language processing technology to detect and classify named entities, such as people, locations, organizations, and so forth. With this tech, you can identify elements in text that are relevant to certain topics or entities related to them. This kind of work is essential for understanding the context of text documents, which can give you better insights. NER can be used in many applications – from making content more searchable and understandable, to helping AI chatbots understand user queries better!"
      ],
      "metadata": {
        "id": "4sAEbvDDwMV2"
      }
    }
  ]
}